# -*- coding: utf-8 -*-
"""Helper functions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qMvmsEyHyfWUz5mSFdLtTsTmgsRb9iLk
"""
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
def view_random_image(target_dir, target_class):
  # saving the target folder name in a variable
  target_folder=target_dir+"/"+target_class

  #Selecting a random image
  random_img=random.sample(os.listdir(target_folder),1)

  #Displaying the random image
  img=mpimage.imread(target_folder+"/" +random_img[0])
  '''
  Here random_img is a list but we need a string in the function hence with
  random_img[0] the list is converted to string on 0 axis'''
  plt.imshow(img)
  plt.title(target_class)
  plt.axis("off");

  print(f"image shape is:{img.shape}")
  return img

#Creating a helper function to plot the loss curves separately
def plot_loss_curve(history):
  training_loss=history.history["loss"]
  val_loss=history.history["val_loss"]
  training_accuracy=history.history["accuracy"]
  val_accuracy=history.history["val_accuracy"]
  epochs=range(len(history.history["loss"]))

  #Loss the loss
  plt.plot(epochs,training_loss, label="Training_loss")
  plt.plot(epochs, val_loss, label="Validation_loss")
  plt.title("Loss")
  plt.xlabel("Epochs")
  plt.legend()

  #Plot accuracy
  plt.figure()
  plt.plot(epochs, training_accuracy, label="Training Accuracy")
  plt.plot(epochs, val_accuracy, label="Validation_Accuracy")
  plt.title("Accuracy")
  plt.xlabel("Epochs")
  plt.legend();

# helper function to load the image and resize it
def load_prep_img (filename, img_shape=224):
  '''
  Read the image from a file name, coverts into tensors and reshape it into 
  (img_shape,img_shape,colour channel)'''
  #Read the target file(image)
  img=tf.io.read_file(filename)

  #Decode the image to tensor with 3 colour channel
  img=tf.image.decode_image(img, channels=3) 
  #tf.image.decode_image(img, channels=3)

  #Resize the image to (224,224) as our model was trained as (224,224,3)
  img=tf.image.resize(img,size=[img_shape,img_shape])

  #Rescale the image
  img=img/255

  return img

def prep_and_plot(filename, model,class_name):
  '''
  it takes input of filename (i.e new unseen image), predicts with model and 
  display the result'''
  #Read the file
  img=tf.io.read_file(filename)

  #Decode the file
  img=tf.image.decode_image(img)

  #Resize and normalize the image
  img=tf.image.resize(img,size=(224,224))/255

  #loads the image
  #img=load_prep_img(filename)# we don't need "load_prep_img" function as it is brought under this function

  #expand one dimention of the read file as the new image file as its shape is
  #(ht,wt,color channel) but model is trained on (batch size, ht, wt,colour channel). 
  #So we need to expand one dimension of the new image so that we can predict on the image

  pred=model.predict(tf.expand_dims(img,axis=0))

  #Get the predicted class
  pred_class=class_names[int(tf.round(pred))]

  #Plot the image
  plt.imshow(img)
  plt.title(f"prediction {pred_class}")
  plt.axis(False);

#Walk through the 'directory name', "filenames" and 'directory path
def walk_through(directory):
  '''Walk through the 'dirname', "filenames" and 'directory path'''
  import os
  for dirpath,dirname, filename in os.walk(directory):
    print(f"There are {len(dirnames)} directories and {len(filepath)} images in '{dirpath}'.")
    
    
  # Create the confustion matrix
  cm = confusion_matrix(y_true, y_pred)
  cm_norm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis] # normalize it
  n_classes = cm.shape[0] # find the number of classes we're dealing with

  # Plot the figure and make it pretty
  fig, ax = plt.subplots(figsize=figsize)
  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better
  fig.colorbar(cax)

  # Are there a list of classes?
  if classes:
    labels = classes
  else:
    labels = np.arange(cm.shape[0])
  
  # Label the axes
  ax.set(title="Confusion Matrix",
         xlabel="Predicted label",
         ylabel="True label",
         xticks=np.arange(n_classes), # create enough axis slots for each class
         yticks=np.arange(n_classes), 
         xticklabels=labels, # axes will labeled with class names (if they exist) or ints
         yticklabels=labels)
  
  # Make x-axis labels appear on bottom
  ax.xaxis.set_label_position("bottom")
  ax.xaxis.tick_bottom()

  # Set the threshold for different colors
  threshold = (cm.max() + cm.min()) / 2.

  # Plot the text on each cell
  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    if norm:
      plt.text(j, i, f"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)",
              horizontalalignment="center",
              color="white" if cm[i, j] > threshold else "black",
              size=text_size)
    else:
      plt.text(j, i, f"{cm[i, j]}",
              horizontalalignment="center",
              color="white" if cm[i, j] > threshold else "black",
              size=text_size)

  # Save the figure to the current working directory
  if savefig:
    fig.savefig("confusion_matrix.png")

import datetime

def create_tensorboard_callback(dir_name, experiment_name):
  """
  Creates a TensorBoard callback instand to store log files.
  Stores log files with the filepath:
    "dir_name/experiment_name/current_datetime/"
  Args:
    dir_name: target directory to store TensorBoard log files
    experiment_name: name of experiment directory (e.g. efficientnet_model_1)
  """
  log_dir = dir_name + "/" + experiment_name + "/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
  tensorboard_callback = tf.keras.callbacks.TensorBoard(
      log_dir=log_dir
  )
  print(f"Saving TensorBoard log files to: {log_dir}")
  return tensorboard_callback

# Plot the validation and training data separately
import matplotlib.pyplot as plt

def plot_loss_curves(history):
  """
  Returns separate loss curves for training and validation metrics.
  Args:
    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)
  """ 
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  accuracy = history.history['accuracy']
  val_accuracy = history.history['val_accuracy']

  epochs = range(len(history.history['loss']))

  # Plot loss
  plt.plot(epochs, loss, label='training_loss')
  plt.plot(epochs, val_loss, label='val_loss')
  plt.title('Loss')
  plt.xlabel('Epochs')
  plt.legend()

  # Plot accuracy
  plt.figure()
  plt.plot(epochs, accuracy, label='training_accuracy')
  plt.plot(epochs, val_accuracy, label='val_accuracy')
  plt.title('Accuracy')
  plt.xlabel('Epochs')
  plt.legend();

def compare_historys(original_history, new_history, initial_epochs=5):
    """
    Compares two TensorFlow model History objects.
    
    Args:
      original_history: History object from original model (before new_history)
      new_history: History object from continued model training (after original_history)
      initial_epochs: Number of epochs in original_history (new_history plot starts from here) 
    """
    
    # Get original history measurements
    acc = original_history.history["accuracy"]
    loss = original_history.history["loss"]

    val_acc = original_history.history["val_accuracy"]
    val_loss = original_history.history["val_loss"]

    # Combine original history with new history
    total_acc = acc + new_history.history["accuracy"]
    total_loss = loss + new_history.history["loss"]

    total_val_acc = val_acc + new_history.history["val_accuracy"]
    total_val_loss = val_loss + new_history.history["val_loss"]

    # Make plots
    plt.figure(figsize=(8, 8))
    plt.subplot(2, 1, 1)
    plt.plot(total_acc, label='Training Accuracy')
    plt.plot(total_val_acc, label='Validation Accuracy')
    plt.plot([initial_epochs-1, initial_epochs-1],
              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')

    plt.subplot(2, 1, 2)
    plt.plot(total_loss, label='Training Loss')
    plt.plot(total_val_loss, label='Validation Loss')
    plt.plot([initial_epochs-1, initial_epochs-1],
              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.xlabel('epoch')
    plt.show()
  
# Create function to unzip a zipfile into current working directory 
# (since we're going to be downloading and unzipping a few files)
import zipfile

def unzip_data(filename):
  """
  Unzips filename into the current working directory.
  Args:
    filename (str): a filepath to a target zip folder to be unzipped.
  """
  zip_ref = zipfile.ZipFile(filename, "r")
  zip_ref.extractall()
  zip_ref.close()
# Function to evaluate: accuracy, precision, recall, f1-score
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def calculate_results(y_true, y_pred):
  """
  Calculates model accuracy, precision, recall and f1 score of a binary classification model.
  Args:
      y_true: true labels in the form of a 1D array
      y_pred: predicted labels in the form of a 1D array
  Returns a dictionary of accuracy, precision, recall, f1-score.
  """
  # Calculate model accuracy
  model_accuracy = accuracy_score(y_true, y_pred) * 100
  # Calculate model precision, recall and f1 score using "weighted average
  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average="weighted")
  model_results = {"accuracy": model_accuracy,
                  "precision": model_precision,
                  "recall": model_recall,
                  "f1": model_f1}
  return model_results
